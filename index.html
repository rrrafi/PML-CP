<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Pml-cp : HAR Prediction">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Pml-cp</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/rrrafi/PML-CP">View on GitHub</a>

          <h1 id="project_title">Pml-cp</h1>
          <h2 id="project_tagline">HAR Prediction</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/rrrafi/PML-CP/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/rrrafi/PML-CP/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>HAR Prediction



<p>

</p>



code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}


<div>


<div id="header">
<h1>
<a id="har-prediction" class="anchor" href="#har-prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>HAR Prediction</h1>
</div>

<p>The machine learning task at hand is predicting the movement a subject made given data from a number of sensors. It is a supervised classification task with mostly continuous features.</p>

<pre><code>## Warning: package 'caret' was built under R version 3.1.2</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
## Loading required package: survival
## Loading required package: splines
## 
## Attaching package: 'survival'
## 
## The following object is masked from 'package:caret':
## 
##     cluster
## 
## Loading required package: parallel
## Loaded gbm 2.1</code></pre>

<div id="pre-processing">
<h1>
<a id="pre-processing" class="anchor" href="#pre-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pre-processing</h1>
<p>The “training”" dataset contains 19622 observations and 160 variables. We split the training dataset further up into a new true training set (75%) and a cross-validation set (25%).</p>
<p>The first seven variables (columns) do not contain variables that are relevant for (generalized) prediction, as they are e.g. the index number, time stamps, and subject names.</p>
<p>A summary of the dataset and its variables (not shown here for space reasons) indicates that, of the 153 feature variables in the dataset, only 52 do not contain a very significant number of NAs. We therefore only consider these 52 features for training.</p>
</div>

<div id="training">
<h1>
<a id="training" class="anchor" href="#training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training</h1>
<div id="simple-tree">
<h2>
<a id="simple-tree" class="anchor" href="#simple-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple tree</h2>
<p>As a baseline, we train a simple tree. We use Caret’s confusionMatrix function to output a number of relevant metrics for the evaluation of the trained classifier.</p>
<pre><code>## Loading required package: rpart</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1275   19   97    0    4
##          B  406  250  293    0    0
##          C  448   11  396    0    0
##          D  371  136  297    0    0
##          E  133   57  299    0  412
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4757          
##                  95% CI : (0.4617, 0.4898)
##     No Information Rate : 0.5369          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : 0.3137          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.4842  0.52854  0.28654       NA  0.99038
## Specificity            0.9472  0.84225  0.86968   0.8361  0.89104
## Pos Pred Value         0.9140  0.26344  0.46316       NA  0.45727
## Neg Pred Value         0.6130  0.94362  0.75648       NA  0.99900
## Prevalence             0.5369  0.09645  0.28181   0.0000  0.08483
## Detection Rate         0.2600  0.05098  0.08075   0.0000  0.08401
## Detection Prevalence   0.2845  0.19352  0.17435   0.1639  0.18373
## Balanced Accuracy      0.7157  0.68539  0.57811       NA  0.94071</code></pre>
</div>

<div id="boosted-tree">
<h2>
<a id="boosted-tree" class="anchor" href="#boosted-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boosted tree</h2>
<p>We can see from the confusion matrix of the simple tree that the classifier still confuses the classes a lot. We therefore now consider a boosted tree. Its output follows below.</p>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1364   18    8    4    1
##          B   32  896   21    0    0
##          C    0   21  822   12    0
##          D    3    3   20  773    5
##          E    1    5    5   14  876
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9647          
##                  95% CI : (0.9592, 0.9697)
##     No Information Rate : 0.2855          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9554          
##  Mcnemar's Test P-Value : 0.0005182       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9743   0.9502   0.9384   0.9626   0.9932
## Specificity            0.9912   0.9866   0.9918   0.9924   0.9938
## Pos Pred Value         0.9778   0.9442   0.9614   0.9614   0.9723
## Neg Pred Value         0.9897   0.9881   0.9867   0.9927   0.9985
## Prevalence             0.2855   0.1923   0.1786   0.1637   0.1799
## Detection Rate         0.2781   0.1827   0.1676   0.1576   0.1786
## Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837
## Balanced Accuracy      0.9827   0.9684   0.9651   0.9775   0.9935</code></pre>
<p>It is evident that the boosted tree improves the classification performance significantly, e.g. raising overall acuracy from 0.50 to 0.97. This is a good performance by any standard and we will use this classifier on the test set.</p>
</div>

<p></p>
</div>

<div id="classification-of-test-set">
<h1>
<a id="classification-of-test-set" class="anchor" href="#classification-of-test-set" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classification of test set</h1>
<p>The test set predictions follow below.</p>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>

<p></p>
</div>







<p>
</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Pml-cp maintained by <a href="https://github.com/rrrafi">rrrafi</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
